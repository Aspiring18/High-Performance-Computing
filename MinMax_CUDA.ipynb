{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JqnkP39qNOw",
        "outputId": "32cac555-d7f0-4463-d35b-2d58a4b89a40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-g8d9b0uu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-g8d9b0uu\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=a1fdbb36659f18e242fafc318ef70f9ddef4b7c95890b90513de2427fc93b491\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ok_tku99/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwABsY6rqGzs",
        "outputId": "383e1c8c-a9d8-4ad7-e3d4-37b4cbad1fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// CUDA kernel for parallel reduction to find minimum value\n",
        "__global__ void parallelMin(const int *arr, int *result, int N) {\n",
        "    extern __shared__ int shared[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data to shared memory\n",
        "    if (index < N) {\n",
        "        shared[tid] = arr[index];\n",
        "    } else {\n",
        "        shared[tid] = INT_MAX;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride && index + stride < N) {\n",
        "            if (shared[tid] > shared[tid + stride]) {\n",
        "                shared[tid] = shared[tid + stride];\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result to global memory\n",
        "    if (tid == 0) {\n",
        "        result[blockIdx.x] = shared[0];\n",
        "    }\n",
        "\n",
        "    // Print thread activity\n",
        "    if (index < N) {\n",
        "        printf(\"Thread %d: Loaded %d\\n\", index, arr[index]);\n",
        "        for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "            if (tid < stride && index + stride < N) {\n",
        "                printf(\"Thread %d: Compared %d with %d\\n\", index, shared[tid], shared[tid + stride]);\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "        if (tid == 0) {\n",
        "            printf(\"Thread %d: Wrote %d to result\\n\", index, shared[0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for parallel reduction to find maximum value\n",
        "__global__ void parallelMax(const int *arr, int *result, int N) {\n",
        "    extern __shared__ int shared[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data to shared memory\n",
        "    if (index < N) {\n",
        "        shared[tid] = arr[index];\n",
        "    } else {\n",
        "        shared[tid] = INT_MIN;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride && index + stride < N) {\n",
        "            if (shared[tid] < shared[tid + stride]) {\n",
        "                shared[tid] = shared[tid + stride];\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result to global memory\n",
        "    if (tid == 0) {\n",
        "        result[blockIdx.x] = shared[0];\n",
        "    }\n",
        "\n",
        "    // Print thread activity\n",
        "    if (index < N) {\n",
        "        printf(\"Thread %d: Loaded %d\\n\", index, arr[index]);\n",
        "        for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "            if (tid < stride && index + stride < N) {\n",
        "                printf(\"Thread %d: Compared %d with %d\\n\", index, shared[tid], shared[tid + stride]);\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "        if (tid == 0) {\n",
        "            printf(\"Thread %d: Wrote %d to result\\n\", index, shared[0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for parallel reduction to find sum\n",
        "__global__ void parallelSum(const int *arr, int *result, int N) {\n",
        "    extern __shared__ int shared[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load data to shared memory\n",
        "    if (index < N) {\n",
        "        shared[tid] = arr[index];\n",
        "    } else {\n",
        "        shared[tid] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride && index + stride < N) {\n",
        "            shared[tid] += shared[tid + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result to global memory\n",
        "    if (tid == 0) {\n",
        "        result[blockIdx.x] = shared[0];\n",
        "    }\n",
        "\n",
        "    // Print thread activity\n",
        "    if (index < N) {\n",
        "        printf(\"Thread %d: Loaded %d\\n\", index, arr[index]);\n",
        "        for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "            if (tid < stride && index + stride < N) {\n",
        "                printf(\"Thread %d: Added %d with %d\\n\", index, shared[tid], shared[tid + stride]);\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "        if (tid == 0) {\n",
        "            printf(\"Thread %d: Wrote %d to result\\n\", index, shared[0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N;\n",
        "    std::cout << \"Enter the size of the array: \";\n",
        "    std::cin >> N;\n",
        "\n",
        "    // Generate random data\n",
        "    int *arr = new int[N];\n",
        "    std::cout << \"Enter elements of the array: \";\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        std::cin >> arr[i];\n",
        "    }\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *device_arr;\n",
        "    cudaMalloc(&device_arr, N * sizeof(int));\n",
        "    cudaMemcpy(device_arr, arr, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid dimensions\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Allocate memory for result on host\n",
        "    int *result_min = new int[gridSize];\n",
        "    int *result_max = new int[gridSize];\n",
        "    int *result_sum = new int[gridSize];\n",
        "\n",
        "    // Allocate memory for result on device\n",
        "    int *device_result_min, *device_result_max, *device_result_sum;\n",
        "    cudaMalloc(&device_result_min, gridSize * sizeof(int));\n",
        "    cudaMalloc(&device_result_max, gridSize * sizeof(int));\n",
        "    cudaMalloc(&device_result_sum, gridSize * sizeof(int));\n",
        "\n",
        "    // Perform parallel reduction to find minimum value\n",
        "    parallelMin<<<gridSize, blockSize, blockSize * sizeof(int)>>>(device_arr, device_result_min, N);\n",
        "\n",
        "    // Perform parallel reduction to find maximum value\n",
        "    parallelMax<<<gridSize, blockSize, blockSize * sizeof(int)>>>(device_arr, device_result_max, N);\n",
        "\n",
        "    // Perform parallel reduction to find sum\n",
        "    parallelSum<<<gridSize, blockSize, blockSize * sizeof(int)>>>(device_arr, device_result_sum, N);\n",
        "\n",
        "    // Copy results from device to host\n",
        "    cudaMemcpy(result_min, device_result_min, gridSize * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(result_max, device_result_max, gridSize * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(result_sum, device_result_sum, gridSize * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Final reduction on host\n",
        "    int min_val = result_min[0];\n",
        "    int max_val = result_max[0];\n",
        "    int sum_val = result_sum[0];\n",
        "    for (int i = 1; i < gridSize; ++i) {\n",
        "        if (result_min[i] < min_val) min_val = result_min[i];\n",
        "        if (result_max[i] > max_val) max_val = result_max[i];\n",
        "        sum_val += result_sum[i];\n",
        "    }\n",
        "\n",
        "    // Print results\n",
        "    std::cout << \"Minimum: \" << min_val << std::endl;\n",
        "    std::cout << \"Maximum: \" << max_val << std::endl;\n",
        "    std::cout << \"Sum: \" << sum_val << std::endl;\n",
        "    std::cout << \"Average: \" << static_cast<double>(sum_val) / N << std::endl;\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(device_arr);\n",
        "    cudaFree(device_result_min);\n",
        "    cudaFree(device_result_max);\n",
        "    cudaFree(device_result_sum);\n",
        "\n",
        "    // Free host memory\n",
        "    delete[] arr;\n",
        "    delete[] result_min;\n",
        "    delete[] result_max;\n",
        "    delete[] result_sum;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction\n",
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixd4ijBLqZtd",
        "outputId": "8ea1f5db-c211-4d1c-e6c1-23c1fbe45140"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the array: 4\n",
            "Enter elements of the array: 12 34 55 67\n",
            "Thread 0: Loaded 12\n",
            "Thread 1: Loaded 34\n",
            "Thread 2: Loaded 55\n",
            "Thread 3: Loaded 67\n",
            "Thread 0: Compared 12 with 55\n",
            "Thread 1: Compared 34 with 67\n",
            "Thread 0: Compared 12 with 34\n",
            "Thread 0: Wrote 12 to result\n",
            "Thread 0: Loaded 12\n",
            "Thread 1: Loaded 34\n",
            "Thread 2: Loaded 55\n",
            "Thread 3: Loaded 67\n",
            "Thread 0: Compared 67 with 55\n",
            "Thread 1: Compared 67 with 67\n",
            "Thread 0: Compared 67 with 67\n",
            "Thread 0: Wrote 67 to result\n",
            "Thread 0: Loaded 12\n",
            "Thread 1: Loaded 34\n",
            "Thread 2: Loaded 55\n",
            "Thread 3: Loaded 67\n",
            "Thread 0: Added 168 with 55\n",
            "Thread 1: Added 101 with 67\n",
            "Thread 0: Added 168 with 101\n",
            "Thread 0: Wrote 168 to result\n",
            "Minimum: 12\n",
            "Maximum: 67\n",
            "Sum: 168\n",
            "Average: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTYp8Eijqfh0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}