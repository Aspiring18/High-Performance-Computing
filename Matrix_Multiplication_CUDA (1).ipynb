{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvcc --version\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiitDHYGQwAu",
        "outputId": "184d7ceb-3130-4cd7-d373-a925ecf306ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-4any113t\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-4any113t\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=7ca17e541c4a029b45cd484b77537c1e5f23c131deb79f78e5f877617bba9385\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3p7teppe/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matrixMultiplication(const int *a, const int *b, int *c, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            sum += a[row * N + i] * b[i * N + col];\n",
        "        }\n",
        "        c[row * N + col] = sum;\n",
        "        printf(\"Thread (%d, %d) is computing c[%d][%d]\\n\", threadIdx.y, threadIdx.x, row, col);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N;\n",
        "    std::cout << \"Enter the size of the square matrices: \";\n",
        "    std::cin >> N;\n",
        "\n",
        "    // Allocate memory for matrices on host\n",
        "    std::vector<int> host_a(N * N);\n",
        "    std::vector<int> host_b(N * N);\n",
        "    std::vector<int> host_c(N * N);\n",
        "\n",
        "    // Input elements of matrices A and B\n",
        "    std::cout << \"Enter elements of matrix A (\" << N << \"x\" << N << \"):\" << std::endl;\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        std::cin >> host_a[i];\n",
        "    }\n",
        "\n",
        "    std::cout << \"Enter elements of matrix B (\" << N << \"x\" << N << \"):\" << std::endl;\n",
        "    for (int i = 0; i < N * N; ++i) {\n",
        "        std::cin >> host_b[i];\n",
        "    }\n",
        "\n",
        "    // Allocate memory for matrices on device\n",
        "    int *device_a, *device_b, *device_c;\n",
        "    cudaMalloc(&device_a, N * N * sizeof(int));\n",
        "    cudaMalloc(&device_b, N * N * sizeof(int));\n",
        "    cudaMalloc(&device_c, N * N * sizeof(int));\n",
        "\n",
        "    // Copy matrices from host to device\n",
        "    cudaMemcpy(device_a, host_a.data(), N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(device_b, host_b.data(), N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockDim(16, 16);\n",
        "    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMultiplication<<<gridDim, blockDim>>>(device_a, device_b, device_c, N);\n",
        "\n",
        "    // Copy result matrix from device to host\n",
        "    cudaMemcpy(host_c.data(), device_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print result matrix\n",
        "    std::cout << \"Result matrix (\" << N << \"x\" << N << \"):\" << std::endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            std::cout << host_c[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(device_a);\n",
        "    cudaFree(device_b);\n",
        "    cudaFree(device_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VASpE6rxTRWG",
        "outputId": "e14fa681-2080-4108-f395-fe3e8962dd15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc mul.cu -o mul\n",
        "!./mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwaTJJxBTeor",
        "outputId": "c9addd4f-3a9f-40c5-f524-05c6cb667c58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the square matrices: 3 \n",
            "Enter elements of matrix A (3x3):\n",
            "1 2 3 \n",
            "5 6 3\n",
            "2 3 4\n",
            "Enter elements of matrix B (3x3):\n",
            "2 3 4\n",
            "5 6 7\n",
            "2 3 4\n",
            "Thread (2, 0) is computing c[2][0]\n",
            "Thread (2, 1) is computing c[2][1]\n",
            "Thread (2, 2) is computing c[2][2]\n",
            "Thread (0, 0) is computing c[0][0]\n",
            "Thread (0, 1) is computing c[0][1]\n",
            "Thread (0, 2) is computing c[0][2]\n",
            "Thread (1, 0) is computing c[1][0]\n",
            "Thread (1, 1) is computing c[1][1]\n",
            "Thread (1, 2) is computing c[1][2]\n",
            "Result matrix (3x3):\n",
            "18 24 30 \n",
            "46 60 74 \n",
            "27 36 45 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMx79J3wTh0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}